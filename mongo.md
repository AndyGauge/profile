----
layout: efi
----
<div id="pageheader">
	<h2><a class="titles" href="./viewtopic.php?f=45&amp;t=2110">json, CAN</a></h2>


</div>

<br clear="all" /><br />

<div id="pagecontent">

						<div class="postbody">so the idea is to talk about mongo db in an implementation prepared to log data that doesn't necessarily have a schema.  So json is a standard that defines data at a state in time.  A sample user of a forum example.<br /><br />Hi my name is Nathan Sparks and I have 42 posts on the diy_efi board.<br /><div class="codewrapper"><div class="codetitle"><b>Code:</b></div><div class="codecontent">user<br />{ _id: BSON_id //a number like 0xb2d91ae6f8416660<br />{first_name: &quot;Nathan&quot;,<br />last_name: &quot;Sparks&quot;,<br />post_count: 42,<br />memberships:<br />{board_name: &quot;diy_efi&quot;}<br />}<br /></div></div><br />Honestly I see the memberships embedded document being deeper but this is for a sample, and I'm trying to keep this simple.  In use in engine management this could be used in combination with the network of sensors standard known as CAN.  It provides banks of sensors so it would look something like this:<br /><div class="codewrapper"><div class="codetitle"><b>Code:</b></div><div class="codecontent">{<br />p_0: 15.0<br />p_1: 0<br />p_5: duh is this getting boring?<br />}</div></div><br />that could be dynamically appended a t value that defines where in the sequence of the logging and that value would be indexed.</div>

						<div class="postbody">perfect place to put un implemented features so if at a later date we have data that is expected to be 0.  we can filter that out easily later.  so _max and _avg can be filtered until the register stars responding like an O2 sensor.  <br /><br />So the engine is at the mercy of the ecu until the feedback from the o2 sensor can keep the engine running.  Before that time, the ecu needs to deal with throttle position, air bypass injection and spark.<br /><br />voltage of the sensor ranges from 100 to 900 mV.  and the current ECU will throw a trouble code if the range remains below 300 or above 800.<br /><div class="codewrapper"><div class="codetitle"><b>Code:</b></div><div class="codecontent">{_id: BSON,<br />o2: 0.134,<br />t_value: 1},<br />&#93;{_id: BSON,<br />o2: 0.1356,<br />t_value: 2},<br />&#93;{_id: BSON,<br />o2: 0.256,<br />t_value: 3},</div></div><br />if I were in the console I could query the data<br /><div class="codewrapper"><div class="codetitle"><b>Code:</b></div><div class="codecontent">db.sensors.find({t_value: {$lt:&nbsp; 4}})</div></div></div>
						<div class="postbody">so it takes event handlers like <br />t_value = now - 150 _avg<br />if we need to evaluate if a sensor has been offline for 150 cycles we need listeners<br />small mongodb instances that are self garbage collecting using capped collections<br />optimized data evaluation<br /><br />This same capped collection can be used to determine a sensor is out of range.<br /><br />Since we don't know many documents per second that we are going to receive we set the capped collection to be tuned on the least number that can be metriced when saving only the single sensor to the database.  Since documents performance are based on size of the document, the best performant implementation can be set as a value based on the test.  <br /><br />You can then gauge your performance when you do a query on the t value for the time range the test was for.  If our isolated test revealed maximized performance tooks 3000 documents and in implementation there were 2000 documents returned from<br /><div class="codewrapper"><div class="codetitle"><b>Code:</b></div><div class="codecontent">db.sensor_log.find({created_at: { $lte: new Timestamp() - 0x10000 } } )</div></div><br /><br />MongoDB support for timestamps <a href="http://docs.mongodb.org/manual/core/document/#timestamps" class="postlink" rel="nofollow" target="_blank">docs.mongodb.org</a><br /><div class="quotewrapper"><div class="quotetitle">mongo reference timestamps wrote:</div><div class="quotecontent">Timestamp values are a 64 bit value where:<br /><br />the first 32 bits are a time_t value (seconds since the Unix epoch)<br />the second 32 bits are an incrementing ordinal for operations within a given second.<br /></div></div></div>
						<div class="postbody">use it as an extaction layor for an existing SQL instance by issuing sql commands and interpreting the results into a JSON log output and output to targit {name to be determined, I know it starts with the letter x and released in a later version of their bi tool; the whole reason I'm implementing it in a data center with the upgraded release version so all the new features unlock as part of the migration] which is designed to show multi dimensional views of predefined unputs.<br /><br />In troubleshooting large sql tables I often start by query with a <br /><div class="codewrapper"><div class="codetitle"><b>Code:</b></div><div class="codecontent">SELECT TOP 1 * from PBAInstanceTable</div></div><br /><br />which returns column names of the table that is used to define a product model which has configuration options for a product like <a href="http://www.rejuvenation.com/catalog/products/kent-quick-ship-ob" class="postlink" rel="nofollow" target="_blank">Kent</a> which can be seen in the <a href="http://www.rejuvenation.com/catalog/products/cascade" class="postlink" rel="nofollow" target="_blank">configuration engine</a>.<br /><br />Options like vaulted, or finish, length, shade are records in sql using referencial number.  I would want another SQL statement to return the collection of these configurations.  By the way it will return pre and post configuration engine variables so you will actually need to filter on that as well if you want to return a single configuration detail set.<br /><div class="codewrapper"><div class="codetitle"><b>Code:</b></div><div class="codecontent">SELECT * from PBATABLEINSTANCE WHERE INVENTTRANSID = {#instance_variable}</div></div><br /><br />I would want to have JSON logging like this<br /><div class="codewrapper"><div class="codetitle"><b>Code:</b></div><div class="codecontent">{ _id: BSON ,<br />query: &quot;SELECT TOP 1 * from PBAInstanceTable&quot;,<br />headers: &quot;INVENTTRANSID, variable, value&quot;<br />rows: &quot;1, pba_model_number, 1&quot;<br />},<br />{_id: BSON,<br />query: &quot;SELECT * from PBATABLEINSTANCE WHERE INVENTTRANSID = 3245&quot;,<br />rows: {<br />3245, pba_model_number, 25<br />3245, finish, &quot;old_brass&quot;,<br />3245, shade, &quot;Mission Satin Etched Flared Shade$35.00&quot;<br />3245, upshade, &quot;Mission Satin Etched Flared Gas-Style Shade$50.00&quot;<br />3245, lights, 8<br />3245, lengths, 36<br />3245, socket, :turnkey<br />3245, vaulted, false<br />}</div></div><br /><br />Asynchronous process at a higher level language can parse this document and run an  update statement that appends to the model embedded document like<br /><div class="codewrapper"><div class="codetitle"><b>Code:</b></div><div class="codecontent">db.pba_instance.find({_id:&nbsp; bson}).shade</div></div><br />Can be queried to return the string<br /><div class="codewrapper"><div class="codetitle"><b>Code:</b></div><div class="codecontent">db.pba_instance.update({_id:&nbsp; bson} , $set : {shade : &quot;Mission Satin Etched Flared Shade$35.00&quot;, state: &quot;processed&quot;}})<br /></div></div><br />The state is the addition of statemachine which allows the document processing state to follow the document.  It allows built in error handling that happens within the document itself.  MongoDB is a great thing to add features like statemachine for some documents, and a capped collection so those that were old fall off and those that were in error which have likely been fixed by the time the error drops off makes for efficient troubleshooting with built in analytics.<br /><br />For example your state machine might be inspecting the model for the product and validating that all of the required config variables exist and if it detects an anomoly against the model it can set the state to <div class="codewrapper"><div class="codetitle"><b>Code:</b></div><div class="codecontent">state: &quot;expecting value for pba_model 25 variables &#91;priority, gu24_bulb, gu24_socket_count&#93;, variables out of range &#91;&#93;&quot;</div></div></div>
						<div class="postbody">now lets say we want to tie in a shutter from an external web cam.<br />we need to tie in an embedded document within the logger with the image captured from the camera so it gets tied to the sensors<br /><br />BSON id begins with the timestamp so just by logging data we get the timestamp and we can log any type of data, since the nature of binary storage is to save raw data.  GridFS is also available if you intend to save very large dumps.  GridFS would be applicable if you wanted to locally save images of computers under version control.  Replication would come in handy but these machines should have a network control task to limit their bandwith, monitored, reported.<br /><br />binary data storage makes storing any types of documents.  UTF-8 seems to work well for me and   file storage, and sensor data are all well optimized <br /><br />The problem comes in with the overhead of a large database engine on top of small memory footprints.  Transactional data being tied directly to point in time better suited application.  User registrations, orders, inventory with relationships are far better suited.  Mongo facilitates this through <a href="http://docs.mongodb.org/manual/reference/database-references/#dbrefs" class="postlink" rel="nofollow" target="_blank">doc ref</a><br /><div class="codewrapper"><div class="codetitle"><b>Code:</b></div><div class="codecontent">user<br />{_id,<br />name: {first: &quot;Andrew&quot;,last: &quot;Gauger&quot;}}<br />order<br />{_id,<br />user: { &quot;$ref&quot; : user, &quot;$id&quot; : BSON}<br /></div></div><br /><div class="codewrapper"><div class="codetitle"><b>Code:</b></div><div class="codecontent">db.order.find( { ... }).user.name,first</div></div></div>
						<div class="postbody">.sensor from laser readings nightly to apollo 1 Gw laser measuring the distance to a trillinth.<br /><div class="codewrapper"><div class="codetitle"><b>Code:</b></div><div class="codecontent">{_id,<br />timestamp: 64bit_int,<br />distance: 356,700.83482019383433<br />}</div></div><br />allows very precise point in time to dynamic events<br /><br />Further precision can be created by continually updating thought the millisecond. These inserts can then be averaged.</div>

						<div class="postbody">oscilllation and synch<br />the per second signal is ignored, it is just log data.  It may come in faster or slower depending on CPU utilization<br /><br />basing distributed storage on universal cycle count of an engine rather than per second or per transaction.<br /><br />In distributed environments dedicated database quickly becomes off loaded.  development works best with a local instance.  Mongo is easy to set up and works in Linux and mac very easily <a href="http://docs.mongodb.org/manual/installation/" class="postlink" rel="nofollow" target="_blank">installation by environment</a></div>
						<div class="postbody">allows abstraction of bi tools to analyze pulse of signal that can be tied to signals that include voltages of every sensor providing feedback<br /><br />Analyzing sensors with direct access to query the signals at different intervals within the stroke will allow tuning control to tie back into the forecasted tables.  It is the only way to reliably test.</div>

						<div class="postbody">controllable multi core<br />assign processes to muliple cores based on number of detected cores as indicated by hearbeat of co processors<br /><br />Ever played a ps3? coda <br /><br /><a href="https://www.google.com/search?q=coda+ps3&amp;aq=f&amp;oq=coda+ps3&amp;aqs=chrome.0.57j0.2562j0&amp;sourceid=chrome&amp;ie=UTF-8&quot;" class="postlink" rel="nofollow" target="_blank">google search</a><br />also an example of point in time data.<br /><br />monitoring of an online app is the single greatest ROI example<br /><br />So here is where things get really interesting.  We no longer need an engine mangement system.  The car is autonomous.  The injectors sense that the key is turned since they received their wake up 1x cam signal.  They know to fire and they will begin to do so.<br /><br />Spark is already calculated at the GM DIS interface  this is really the basis of the project.  This is where a 6 and 1 7x signal is translated to 3x which will inform the system of the 3x signal and the injectors will self align since they have their own computer chip in line with the harness that receives the CAN signal.This cpu is responsible for sending the MAP and CHT back to the system.</div>
						<div class="postbody">If multiple cores of co processors and I need to re google incase it was cuda processors.<br />We timestamp whenever the processor is able to process in the most thread safe manner<br /><br />Also designing the system to handle failures by passing through the original voltage back through the harness.  an inline fail back controller exists inline with the existing ecu as backup</div>
</div>
